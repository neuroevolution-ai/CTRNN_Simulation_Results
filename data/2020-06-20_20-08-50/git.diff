diff --git a/configurations/default.json b/configurations/default.json
index 4c9dcea..4a2893c 100644
--- a/configurations/default.json
+++ b/configurations/default.json
@@ -1,7 +1,7 @@
 {
   "environment": "Ant-v2",
   "random_seed": 0,
-  "number_generations": 50,
+  "number_generations": 250,
   "use_worker_processes": true,
   "optimizer": {
     "type": "MU_ES",
@@ -14,8 +14,8 @@
     "extra_from_hof": 5,
     "lambda_": 500,
     "mutpb": 0.8,
-    "distance": "NCD",
-    "max_recorded_behaviors": 100,
+    "distance": "euclid",
+    "max_recorded_behaviors": 20,
     "recorded_behaviors_per_generation": 5,
     "novelty_nearest_k": 5,
     "novelty_weight": 1
@@ -48,8 +48,8 @@
     "max_steps_per_run": 0,
     "max_steps_penalty": 0,
     "reuse_env": true,
-    "behavioral_interval": 1,
-    "behavioral_max_length": 300,
+    "behavioral_interval": 20,
+    "behavioral_max_length": 10,
     "behavior_from_observation": true
   }
 }
diff --git a/neuro_evolution_ctrnn/brains/continuous_time_rnn.py b/neuro_evolution_ctrnn/brains/continuous_time_rnn.py
index c0dfa79..acede3c 100644
--- a/neuro_evolution_ctrnn/brains/continuous_time_rnn.py
+++ b/neuro_evolution_ctrnn/brains/continuous_time_rnn.py
@@ -126,7 +126,7 @@ class ContinuousTimeRNN(IBrain[ContinuousTimeRNNCfg]):
         else:
             self.y = np.clip(self.y, self.clipping_range_min, self.clipping_range_max)
 
-        o: Union[np.ndarray, np.generic] = np.tanh(np.dot(self.y, self.T.toarray()))
+        o: Union[np.ndarray, np.generic] = np.tanh(self.T.T.dot(self.y))
         return o
 
     @classmethod
diff --git a/neuro_evolution_ctrnn/tools/algorithms.py b/neuro_evolution_ctrnn/tools/algorithms.py
index 3ab83f1..6f111e1 100644
--- a/neuro_evolution_ctrnn/tools/algorithms.py
+++ b/neuro_evolution_ctrnn/tools/algorithms.py
@@ -7,6 +7,7 @@ from deap.algorithms import varOr
 from deap import tools
 from bz2 import compress, decompress
 from itertools import tee
+import struct
 
 
 def eaMuPlusLambda(toolbox, ngen, verbose=__debug__,
@@ -81,11 +82,13 @@ def eaMuPlusLambda(toolbox, ngen, verbose=__debug__,
 def calc_novelty(res, results_recorded, get_distance, k):
     """calculate the average distance to the k nearest neighbors"""
     behavior_compressed = res[1]
-    behavior = list(decompress(behavior_compressed))
+    behavior_data = decompress(behavior_compressed)
+    behavior = np.frombuffer(behavior_data, dtype=np.float16)
     dist_list = []
     for rec_res in results_recorded:
         recorded_behavior_compressed = rec_res[1]
-        recorded_behavior = list(decompress(recorded_behavior_compressed))
+        recorded_behavior_data = decompress(recorded_behavior_compressed)
+        recorded_behavior = np.frombuffer(recorded_behavior_data, dtype=np.float16)
         dist = get_distance(a=behavior, b=recorded_behavior, a_len=len(behavior_compressed),
                             b_len=len(recorded_behavior_compressed))
         dist_list.append(dist)
diff --git a/neuro_evolution_ctrnn/tools/env_handler.py b/neuro_evolution_ctrnn/tools/env_handler.py
index 68e1fd0..26d0119 100644
--- a/neuro_evolution_ctrnn/tools/env_handler.py
+++ b/neuro_evolution_ctrnn/tools/env_handler.py
@@ -1,6 +1,5 @@
 import gym
 import logging
-from gym.envs.algorithmic.algorithmic_env import AlgorithmicEnv
 from gym.wrappers.atari_preprocessing import AtariPreprocessing
 from tools.configurations import EpisodeRunnerCfg
 
@@ -9,7 +8,6 @@ from bz2 import BZ2Compressor
 from typing import Union, Iterable
 import numpy as np
 
-
 class EnvHandler:
     """this class creates and modifies openAI-Environment."""
 
@@ -63,7 +61,14 @@ class BehaviorWrapper(Wrapper):
         return super(BehaviorWrapper, self).reset(**kwargs)
 
     def _record(self, data):
-        self.compressed_behavior += self.compressor.compress(bytearray(data))
+        # self.compressed_behavior += self.compressor.compress(bytearray(data))
+        # self.compressed_behavior += self.compressor.compress(data)
+
+        # floatlist = list(data)
+        # self.compressed_behavior += self.compressor.compress(struct.pack('%sf' % len(floatlist), *floatlist))
+
+        data_bytes = np.array(data).astype(np.float16).tobytes()
+        self.compressed_behavior += self.compressor.compress(data_bytes)
 
     def step(self, action: Union[int, Iterable[int]]):
         ob, rew, done, info = super(BehaviorWrapper, self).step(action)
@@ -78,7 +83,15 @@ class BehaviorWrapper(Wrapper):
                 # mass = model.body_mass
                 # xpos = model.data.xipos
                 # pos = (np.sum(mass * xpos, 0) / np.sum(mass))
-                self._record(self.env.unwrapped.model.stat.center)
+
+                # self._record(self.env.unwrapped.model.stat.center)
+                # print(type(self.env.unwrapped.sim.data.qpos.flat))
+                # print(self.env.unwrapped.sim.data.qpos.flat)
+                # self._record(self.env.unwrapped.model.stat.center.flat)
+
+                # since float16.max is only around 65500, we need to make it a little smaller
+                data = np.array(self.env.unwrapped.sim.data.qpos.flat) * 10e-3
+                self._record(data)
             elif self.env.spec.id.endswith("NoFrameskip-v4"):
                 # this is an atari env
                 # noinspection PyProtectedMember
diff --git a/neuro_evolution_ctrnn/tools/experiment.py b/neuro_evolution_ctrnn/tools/experiment.py
index 32643af..aad9007 100644
--- a/neuro_evolution_ctrnn/tools/experiment.py
+++ b/neuro_evolution_ctrnn/tools/experiment.py
@@ -101,7 +101,7 @@ class Experiment(object):
         start_time = time.time()
 
         DaskHandler.init_dask(self.optimizer_class.create_classes, self.brain_class)
-        if self.config.episode_runner.reuse_env:
+        if self.config.episode_runner.reuse_env and self.config.use_worker_processes:
             DaskHandler.init_workers_with_env(self.env_template.spec.id, self.config.episode_runner)
         log = self.optimizer.train(number_generations=self.config.number_generations)
         print("Time elapsed: %s" % (time.time() - start_time))
diff --git a/neuro_evolution_ctrnn/tools/helper.py b/neuro_evolution_ctrnn/tools/helper.py
index c93bac1..1be3fb0 100644
--- a/neuro_evolution_ctrnn/tools/helper.py
+++ b/neuro_evolution_ctrnn/tools/helper.py
@@ -13,7 +13,6 @@ from tools.configurations import ExperimentCfg, OptimizerCmaEsCfg, EpisodeRunner
     IBrainCfg, OptimizerMuLambdaCfg, IOptimizerCfg
 
 
-
 def output_to_action(output, action_space):
     if isinstance(action_space, gym.spaces.Discrete):
         return np.argmax(output)
@@ -147,4 +146,8 @@ def euklidian_distance(a, b, a_len=None, b_len=None):
     x = min(len(a), len(b))
     b = b[:x]
     a = a[:x]
+    # b[b < np.finfo(np.float16).min / 2] = 0
+    # b[b > np.finfo(np.float16).max / 2] = 0
+    # a[a < np.finfo(np.float16).min / 2] = 0
+    # a[a > np.finfo(np.float16).max / 2] = 0
     return np.linalg.norm(a - b)
